{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow0YKqYotBIU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Telco-Customer-Churn.csv')\n",
        "\n",
        "# Preview the first few rows\n",
        "print(df.head())\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "pMti49nVDo22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'TotalCharges' to numeric (some are missing or blank)\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Fill missing values\n",
        "df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)\n"
      ],
      "metadata": {
        "id": "Pxs9Amc6ECXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "kzi56eJfES07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd # Import pandas just in case it's needed for value_counts\n",
        "\n",
        "# Reload the dataset to ensure 'Churn' column is present\n",
        "df = pd.read_csv('Telco-Customer-Churn.csv')\n",
        "\n",
        "# Check value counts of Churn at the start of the cell\n",
        "print(\"Value counts of df['Churn'] at the start of the cell:\")\n",
        "print(df['Churn'].value_counts())\n",
        "\n",
        "# Separate target variable\n",
        "y = df['Churn']\n",
        "X = df.drop('Churn', axis=1)\n",
        "\n",
        "# Print value counts of y after separation\n",
        "print(\"Value counts of y after separation:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Encode binary columns in X\n",
        "binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
        "for col in binary_cols:\n",
        "    X[col] = X[col].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# One-hot encode remaining categorical variables in X\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Encode the target variable y\n",
        "y = y.map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Print value counts of y after mapping\n",
        "print(\"\\nValue counts of y after mapping:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Keep X and y separate for model training"
      ],
      "metadata": {
        "id": "v0Atl5z2E9NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Train-test split on the prepared X and y\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "joblib.dump(model, \"model.joblib\")\n",
        "\n",
        "# Evaluation\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Save the classification report as a JSON file\n",
        "with open(\"classification_report.json\", \"w\") as f:\n",
        "    json.dump(report_dict, f)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm)\n",
        "cm_df.to_csv('confusion_matrix.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK_HlrZGF4ZA",
        "outputId": "eef0d5ac-a545-49e3-8b77-5e3445c54279"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1432  107]\n",
            " [ 329  245]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87      1539\n",
            "           1       0.70      0.43      0.53       574\n",
            "\n",
            "    accuracy                           0.79      2113\n",
            "   macro avg       0.75      0.68      0.70      2113\n",
            "weighted avg       0.78      0.79      0.78      2113\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Feature importance\n",
        "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "top_features = importances.sort_values(ascending=False).head(10)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_features.values, y=top_features.index)\n",
        "plt.title(\"Top 10 Features Influencing Churn\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xwW2E-gVLKwx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}